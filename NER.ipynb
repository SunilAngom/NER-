{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwTmC18qyHJmk2rXldYxRf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrNktjLQH-d-","executionInfo":{"status":"ok","timestamp":1768489534414,"user_tz":-330,"elapsed":22400,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}},"outputId":"f610d294-9d0e-436c-ddff-b5a54b786d95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Collecting pandas\n","  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n","Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n","Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n","Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn, pandas\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.6.1\n","    Uninstalling scikit-learn-1.6.1:\n","      Successfully uninstalled scikit-learn-1.6.1\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-2.3.3 scikit-learn-1.8.0\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["# STEP 1: Install Dependencies\n","\n","!pip install -U spacy pandas scikit-learn tqdm\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"code","source":["# STEP 2: Import Libraries\n","\n","import pandas as pd\n","import spacy\n","from spacy.training import Example\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm"],"metadata":{"id":"zxsWpqcJMNe7","executionInfo":{"status":"ok","timestamp":1768489561712,"user_tz":-330,"elapsed":2772,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# STEP 3: Load Dataset\n","\n","df = pd.read_csv(\"NER_dataset.csv\", encoding='latin1')\n","\n","# Expected columns:\n","# Sentence | Entity | Label\n"],"metadata":{"id":"uQXaM-WkMiiO","executionInfo":{"status":"ok","timestamp":1768489641459,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# STEP 4: Convert to spaCy Format\n","\n","training_data = []\n","current_sentence_words = []\n","current_sentence_tags = []\n","\n","# Using tqdm to show progress\n","for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing dataset to spaCy format\"):\n","    word = str(row['Word'])\n","    ner_tag = str(row['Tag'])  # e.g., 'O', 'B-PER', 'I-PER'\n","\n","    # Check if a new sentence starts\n","    if pd.notna(row['Sentence #']):\n","        # Process the previous sentence if it exists\n","        if current_sentence_words:\n","            full_text = \" \".join(current_sentence_words)\n","            entities = []\n","            current_entity_start_char = -1\n","            current_entity_label = None\n","            word_start_char = 0  # Tracks character offset in full_text\n","\n","            for word_idx, (w, tag) in enumerate(zip(current_sentence_words, current_sentence_tags)):\n","                if tag.startswith('B-'):\n","                    # If an entity was ongoing, close it before starting a new one\n","                    if current_entity_start_char != -1:\n","                        entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","                    current_entity_start_char = word_start_char\n","                    current_entity_label = tag[2:]  # Extract label, e.g., 'PER' from 'B-PER'\n","                elif tag.startswith('I-'):\n","                    # Continue entity, but handle potential errors in IOB sequencing\n","                    # If no B-tag preceded or label mismatch, treat as new B-tag for robustness\n","                    if current_entity_start_char == -1 or current_entity_label != tag[2:]:\n","                        if current_entity_start_char != -1:\n","                            entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","                        current_entity_start_char = word_start_char\n","                        current_entity_label = tag[2:]\n","                elif tag == 'O':\n","                    if current_entity_start_char != -1:  # Entity just ended\n","                        entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","                    current_entity_start_char = -1  # Reset\n","                    current_entity_label = None\n","\n","                word_start_char += len(w) + 1  # +1 for the space after the word\n","\n","            # After processing all words in a sentence, check if an entity was still ongoing\n","            if current_entity_start_char != -1:\n","                entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","\n","            training_data.append((full_text, {\"entities\": entities}))\n","\n","        # Reset for the new sentence\n","        current_sentence_words = [word]\n","        current_sentence_tags = [ner_tag]\n","    else:\n","        # Continue adding words and tags to the current sentence\n","        current_sentence_words.append(word)\n","        current_sentence_tags.append(ner_tag)\n","\n","# After the loop, process the very last sentence\n","if current_sentence_words:\n","    full_text = \" \".join(current_sentence_words)\n","    entities = []\n","    current_entity_start_char = -1\n","    current_entity_label = None\n","    word_start_char = 0\n","\n","    for word_idx, (w, tag) in enumerate(zip(current_sentence_words, current_sentence_tags)):\n","        if tag.startswith('B-'):\n","            if current_entity_start_char != -1:\n","                entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","            current_entity_start_char = word_start_char\n","            current_entity_label = tag[2:]\n","        elif tag.startswith('I-'):\n","            if current_entity_start_char == -1 or current_entity_label != tag[2:]:\n","                if current_entity_start_char != -1:\n","                    entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","                current_entity_start_char = word_start_char\n","                current_entity_label = tag[2:]\n","        elif tag == 'O':\n","            if current_entity_start_char != -1:\n","                entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","            current_entity_start_char = -1\n","            current_entity_label = None\n","        word_start_char += len(w) + 1\n","\n","    if current_entity_start_char != -1:\n","        entities.append((current_entity_start_char, word_start_char - 1, current_entity_label))\n","\n","    training_data.append((full_text, {\"entities\": entities}))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llW6LkFWMrKu","executionInfo":{"status":"ok","timestamp":1768489668452,"user_tz":-330,"elapsed":86,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}},"outputId":"db0b010c-fa62-4750-9aeb-d6183438d420"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing dataset to spaCy format: 100%|██████████| 2307/2307 [00:00<00:00, 28834.43it/s]\n"]}]},{"cell_type":"code","source":["# STEP 5: Train-Test Split\n","\n","train_data, test_data = train_test_split(\n","    training_data, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"tPPqfiFLMyNv","executionInfo":{"status":"ok","timestamp":1768489695074,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# STEP 6: Load spaCy Model\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","ner = nlp.get_pipe(\"ner\")"],"metadata":{"id":"FDPQ7CoUM1wY","executionInfo":{"status":"ok","timestamp":1768489709469,"user_tz":-330,"elapsed":652,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# STEP 7: Add Labels\n","\n","for _, annotations in train_data:\n","    for ent in annotations[\"entities\"]:\n","        ner.add_label(ent[2])"],"metadata":{"id":"QER7WQsWM5hw","executionInfo":{"status":"ok","timestamp":1768489723339,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# STEP 8: Train Model\n","\n","other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n","\n","with nlp.disable_pipes(*other_pipes):\n","    optimizer = nlp.resume_training()\n","\n","    for epoch in range(20):\n","        losses = {}\n","        for text, annotations in tqdm(train_data):\n","            doc = nlp.make_doc(text)\n","            example = Example.from_dict(doc, annotations)\n","            nlp.update([example], drop=0.5, losses=losses)\n","        print(f\"Epoch {epoch+1}, Loss:\", losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7dGus5BM9Bp","executionInfo":{"status":"ok","timestamp":1768489773179,"user_tz":-330,"elapsed":35082,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}},"outputId":"f23e13da-a58f-4362-859d-f351a26c76ee"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 47.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: {'ner': np.float32(286.62292)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 48.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Loss: {'ner': np.float32(187.12917)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Loss: {'ner': np.float32(282.95312)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:02<00:00, 37.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Loss: {'ner': np.float32(164.0441)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 43.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Loss: {'ner': np.float32(140.36494)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:02<00:00, 29.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6, Loss: {'ner': np.float32(92.44096)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:02<00:00, 37.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7, Loss: {'ner': np.float32(96.154396)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8, Loss: {'ner': np.float32(90.816246)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9, Loss: {'ner': np.float32(69.128586)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 45.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10, Loss: {'ner': np.float32(66.30458)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 51.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11, Loss: {'ner': np.float32(52.829304)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 51.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12, Loss: {'ner': np.float32(43.43938)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13, Loss: {'ner': np.float32(52.92191)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14, Loss: {'ner': np.float32(47.334465)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 49.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15, Loss: {'ner': np.float32(34.687294)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 44.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16, Loss: {'ner': np.float32(35.89217)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 46.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17, Loss: {'ner': np.float32(25.828316)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18, Loss: {'ner': np.float32(41.544777)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19, Loss: {'ner': np.float32(29.973618)}\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 50.68it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 20, Loss: {'ner': np.float32(20.888296)}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# STEP 9: Save Model\n","\n","nlp.to_disk(\"/content/ner_model\")"],"metadata":{"id":"fk1u7FnBNMZ7","executionInfo":{"status":"ok","timestamp":1768489801310,"user_tz":-330,"elapsed":150,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# STEP 10: Load Model for Testing\n","\n","nlp_test = spacy.load(\"/content/ner_model\")"],"metadata":{"id":"AmBokOv-NSlt","executionInfo":{"status":"ok","timestamp":1768489841367,"user_tz":-330,"elapsed":454,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# STEP 11: Test on New Sentence\n","\n","text = \"Microsoft was founded by Bill Gates in USA\"\n","doc = nlp_test(text)\n","\n","print(\"\\nPredicted Entities:\")\n","for ent in doc.ents:\n","    print(ent.text, \"->\", ent.label_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKdNbQRgNaff","executionInfo":{"status":"ok","timestamp":1768489866396,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}},"outputId":"09bf87f1-66d7-4ada-a506-e1ffabcd8fca"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Predicted Entities:\n","Microsoft -> org\n","Bill Gates in USA -> org\n"]}]},{"cell_type":"code","source":["# STEP 12: Evaluate on Test Data\n","\n","correct = 0\n","total = 0\n","\n","for text, annotations in test_data:\n","    doc = nlp_test(text)\n","    predicted = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n","    actual = annotations[\"entities\"]\n","\n","    for ent in actual:\n","        total += 1\n","        if ent in predicted:\n","            correct += 1\n","\n","accuracy = correct / total if total > 0 else 0\n","print(\"\\nTest Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUj4N-HDNwzS","executionInfo":{"status":"ok","timestamp":1768489967332,"user_tz":-330,"elapsed":157,"user":{"displayName":"Sunil angom","userId":"15171096641117439119"}},"outputId":"468d7af7-6683-4917-ecdb-7434414a68e8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.8888888888888888\n"]}]}]}